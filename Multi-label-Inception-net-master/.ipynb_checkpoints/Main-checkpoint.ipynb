{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型的训练与预测\n",
    "  首先训练模型并保存，然后在预测的时候读取模型并将结果保存目标格式\n",
    "    * 模型训练首先要将图片保存为tensowflow所需格式，所以第一次训练的时候很慢，但之后就好了\n",
    "    * 模型预测要注意图片是否损坏及格式问题\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for images in 'multi-label'\n",
      "100 bottleneck files created.\n",
      "200 bottleneck files created.\n",
      "300 bottleneck files created.\n",
      "400 bottleneck files created.\n",
      "500 bottleneck files created.\n",
      "600 bottleneck files created.\n",
      "700 bottleneck files created.\n",
      "800 bottleneck files created.\n",
      "900 bottleneck files created.\n",
      "1000 bottleneck files created.\n",
      "1100 bottleneck files created.\n",
      "1200 bottleneck files created.\n",
      "1300 bottleneck files created.\n",
      "1400 bottleneck files created.\n",
      "1500 bottleneck files created.\n",
      "1600 bottleneck files created.\n",
      "1700 bottleneck files created.\n",
      "1800 bottleneck files created.\n",
      "1900 bottleneck files created.\n",
      "2000 bottleneck files created.\n",
      "2100 bottleneck files created.\n",
      "2200 bottleneck files created.\n",
      "2300 bottleneck files created.\n",
      "2400 bottleneck files created.\n",
      "2500 bottleneck files created.\n",
      "2600 bottleneck files created.\n",
      "2700 bottleneck files created.\n",
      "2800 bottleneck files created.\n",
      "2900 bottleneck files created.\n",
      "3000 bottleneck files created.\n",
      "3100 bottleneck files created.\n",
      "3200 bottleneck files created.\n",
      "3300 bottleneck files created.\n",
      "3400 bottleneck files created.\n",
      "3500 bottleneck files created.\n",
      "3600 bottleneck files created.\n",
      "3700 bottleneck files created.\n",
      "3800 bottleneck files created.\n",
      "3900 bottleneck files created.\n",
      "4000 bottleneck files created.\n",
      "4100 bottleneck files created.\n",
      "4200 bottleneck files created.\n",
      "4300 bottleneck files created.\n",
      "4400 bottleneck files created.\n",
      "4500 bottleneck files created.\n",
      "4600 bottleneck files created.\n",
      "4700 bottleneck files created.\n",
      "4800 bottleneck files created.\n",
      "4900 bottleneck files created.\n",
      "5000 bottleneck files created.\n",
      "5100 bottleneck files created.\n",
      "5200 bottleneck files created.\n",
      "5300 bottleneck files created.\n",
      "5400 bottleneck files created.\n",
      "5500 bottleneck files created.\n",
      "5600 bottleneck files created.\n",
      "5700 bottleneck files created.\n",
      "5800 bottleneck files created.\n",
      "5900 bottleneck files created.\n",
      "6000 bottleneck files created.\n",
      "6100 bottleneck files created.\n",
      "6200 bottleneck files created.\n",
      "6300 bottleneck files created.\n",
      "6400 bottleneck files created.\n",
      "6500 bottleneck files created.\n",
      "6600 bottleneck files created.\n",
      "6700 bottleneck files created.\n",
      "6800 bottleneck files created.\n",
      "6900 bottleneck files created.\n",
      "7000 bottleneck files created.\n",
      "7100 bottleneck files created.\n",
      "7200 bottleneck files created.\n",
      "7300 bottleneck files created.\n",
      "7400 bottleneck files created.\n",
      "7500 bottleneck files created.\n",
      "7600 bottleneck files created.\n",
      "7700 bottleneck files created.\n",
      "7800 bottleneck files created.\n",
      "7900 bottleneck files created.\n",
      "8000 bottleneck files created.\n",
      "8100 bottleneck files created.\n",
      "8200 bottleneck files created.\n",
      "8300 bottleneck files created.\n",
      "8400 bottleneck files created.\n",
      "8500 bottleneck files created.\n",
      "8600 bottleneck files created.\n",
      "8700 bottleneck files created.\n",
      "8800 bottleneck files created.\n",
      "8900 bottleneck files created.\n",
      "9000 bottleneck files created.\n",
      "9100 bottleneck files created.\n",
      "9200 bottleneck files created.\n",
      "9300 bottleneck files created.\n",
      "9400 bottleneck files created.\n",
      "9500 bottleneck files created.\n",
      "9600 bottleneck files created.\n",
      "9700 bottleneck files created.\n",
      "9800 bottleneck files created.\n",
      "9900 bottleneck files created.\n",
      "10000 bottleneck files created.\n",
      "10100 bottleneck files created.\n",
      "10200 bottleneck files created.\n",
      "10300 bottleneck files created.\n",
      "10400 bottleneck files created.\n",
      "10500 bottleneck files created.\n",
      "10600 bottleneck files created.\n",
      "10700 bottleneck files created.\n",
      "10800 bottleneck files created.\n",
      "10900 bottleneck files created.\n",
      "11000 bottleneck files created.\n",
      "11100 bottleneck files created.\n",
      "11200 bottleneck files created.\n",
      "11300 bottleneck files created.\n",
      "11400 bottleneck files created.\n",
      "11500 bottleneck files created.\n",
      "11600 bottleneck files created.\n",
      "11700 bottleneck files created.\n",
      "11800 bottleneck files created.\n",
      "11900 bottleneck files created.\n",
      "12000 bottleneck files created.\n",
      "12100 bottleneck files created.\n",
      "12200 bottleneck files created.\n",
      "12300 bottleneck files created.\n",
      "12400 bottleneck files created.\n",
      "12500 bottleneck files created.\n",
      "12600 bottleneck files created.\n",
      "12700 bottleneck files created.\n",
      "12800 bottleneck files created.\n",
      "12900 bottleneck files created.\n",
      "13000 bottleneck files created.\n",
      "13100 bottleneck files created.\n",
      "13200 bottleneck files created.\n",
      "13300 bottleneck files created.\n",
      "13400 bottleneck files created.\n",
      "13500 bottleneck files created.\n",
      "13600 bottleneck files created.\n",
      "13700 bottleneck files created.\n",
      "13800 bottleneck files created.\n",
      "13900 bottleneck files created.\n",
      "14000 bottleneck files created.\n",
      "14100 bottleneck files created.\n",
      "14200 bottleneck files created.\n",
      "14300 bottleneck files created.\n",
      "14400 bottleneck files created.\n",
      "14500 bottleneck files created.\n",
      "14600 bottleneck files created.\n",
      "14700 bottleneck files created.\n",
      "14800 bottleneck files created.\n",
      "14900 bottleneck files created.\n",
      "15000 bottleneck files created.\n",
      "15100 bottleneck files created.\n",
      "15200 bottleneck files created.\n",
      "15300 bottleneck files created.\n",
      "15400 bottleneck files created.\n",
      "15500 bottleneck files created.\n",
      "15600 bottleneck files created.\n",
      "15700 bottleneck files created.\n",
      "15800 bottleneck files created.\n",
      "15900 bottleneck files created.\n",
      "16000 bottleneck files created.\n",
      "16100 bottleneck files created.\n",
      "16200 bottleneck files created.\n",
      "16300 bottleneck files created.\n",
      "16400 bottleneck files created.\n",
      "16500 bottleneck files created.\n",
      "16600 bottleneck files created.\n",
      "16700 bottleneck files created.\n",
      "16800 bottleneck files created.\n",
      "16900 bottleneck files created.\n",
      "17000 bottleneck files created.\n",
      "17100 bottleneck files created.\n",
      "17200 bottleneck files created.\n",
      "17300 bottleneck files created.\n",
      "17400 bottleneck files created.\n",
      "17500 bottleneck files created.\n",
      "17600 bottleneck files created.\n",
      "17700 bottleneck files created.\n",
      "17800 bottleneck files created.\n",
      "17900 bottleneck files created.\n",
      "18000 bottleneck files created.\n",
      "18100 bottleneck files created.\n",
      "18200 bottleneck files created.\n",
      "18300 bottleneck files created.\n",
      "18400 bottleneck files created.\n",
      "18500 bottleneck files created.\n",
      "18600 bottleneck files created.\n",
      "18700 bottleneck files created.\n",
      "18800 bottleneck files created.\n",
      "18900 bottleneck files created.\n",
      "19000 bottleneck files created.\n",
      "19100 bottleneck files created.\n",
      "19200 bottleneck files created.\n",
      "19300 bottleneck files created.\n",
      "19400 bottleneck files created.\n",
      "19500 bottleneck files created.\n",
      "19600 bottleneck files created.\n",
      "19700 bottleneck files created.\n",
      "19800 bottleneck files created.\n",
      "19900 bottleneck files created.\n",
      "20000 bottleneck files created.\n",
      "20100 bottleneck files created.\n",
      "20200 bottleneck files created.\n",
      "20300 bottleneck files created.\n",
      "20400 bottleneck files created.\n",
      "20500 bottleneck files created.\n",
      "20600 bottleneck files created.\n",
      "20700 bottleneck files created.\n",
      "20800 bottleneck files created.\n",
      "20900 bottleneck files created.\n",
      "21000 bottleneck files created.\n",
      "21100 bottleneck files created.\n",
      "21200 bottleneck files created.\n",
      "21300 bottleneck files created.\n",
      "21400 bottleneck files created.\n",
      "21500 bottleneck files created.\n",
      "21600 bottleneck files created.\n",
      "21700 bottleneck files created.\n",
      "21800 bottleneck files created.\n",
      "21900 bottleneck files created.\n",
      "22000 bottleneck files created.\n",
      "22100 bottleneck files created.\n",
      "22200 bottleneck files created.\n",
      "22300 bottleneck files created.\n",
      "22400 bottleneck files created.\n",
      "22500 bottleneck files created.\n",
      "22600 bottleneck files created.\n",
      "22700 bottleneck files created.\n",
      "22800 bottleneck files created.\n",
      "22900 bottleneck files created.\n",
      "23000 bottleneck files created.\n",
      "23100 bottleneck files created.\n",
      "23200 bottleneck files created.\n",
      "23300 bottleneck files created.\n",
      "23400 bottleneck files created.\n",
      "23500 bottleneck files created.\n",
      "23600 bottleneck files created.\n",
      "23700 bottleneck files created.\n",
      "23800 bottleneck files created.\n",
      "23900 bottleneck files created.\n",
      "24000 bottleneck files created.\n",
      "24100 bottleneck files created.\n",
      "24200 bottleneck files created.\n",
      "24300 bottleneck files created.\n",
      "24400 bottleneck files created.\n",
      "24500 bottleneck files created.\n",
      "24600 bottleneck files created.\n",
      "24700 bottleneck files created.\n",
      "24800 bottleneck files created.\n",
      "24900 bottleneck files created.\n",
      "25000 bottleneck files created.\n",
      "25100 bottleneck files created.\n",
      "25200 bottleneck files created.\n",
      "25300 bottleneck files created.\n",
      "25400 bottleneck files created.\n",
      "25500 bottleneck files created.\n",
      "25600 bottleneck files created.\n",
      "25700 bottleneck files created.\n",
      "25800 bottleneck files created.\n",
      "25900 bottleneck files created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26000 bottleneck files created.\n",
      "26100 bottleneck files created.\n",
      "26200 bottleneck files created.\n",
      "26300 bottleneck files created.\n",
      "26400 bottleneck files created.\n",
      "26500 bottleneck files created.\n",
      "26600 bottleneck files created.\n",
      "26700 bottleneck files created.\n",
      "26800 bottleneck files created.\n",
      "26900 bottleneck files created.\n",
      "27000 bottleneck files created.\n",
      "27100 bottleneck files created.\n",
      "27200 bottleneck files created.\n",
      "27300 bottleneck files created.\n",
      "27400 bottleneck files created.\n",
      "27500 bottleneck files created.\n",
      "27600 bottleneck files created.\n",
      "27700 bottleneck files created.\n",
      "27800 bottleneck files created.\n",
      "27900 bottleneck files created.\n",
      "28000 bottleneck files created.\n",
      "28100 bottleneck files created.\n",
      "28200 bottleneck files created.\n",
      "28300 bottleneck files created.\n",
      "28400 bottleneck files created.\n",
      "28500 bottleneck files created.\n",
      "28600 bottleneck files created.\n",
      "28700 bottleneck files created.\n",
      "28800 bottleneck files created.\n",
      "28900 bottleneck files created.\n",
      "29000 bottleneck files created.\n",
      "29100 bottleneck files created.\n",
      "29200 bottleneck files created.\n",
      "29300 bottleneck files created.\n",
      "29400 bottleneck files created.\n",
      "29500 bottleneck files created.\n",
      "29600 bottleneck files created.\n",
      "29700 bottleneck files created.\n",
      "29800 bottleneck files created.\n",
      "29900 bottleneck files created.\n",
      "30000 bottleneck files created.\n",
      "30100 bottleneck files created.\n",
      "30200 bottleneck files created.\n",
      "30300 bottleneck files created.\n",
      "30400 bottleneck files created.\n",
      "30500 bottleneck files created.\n",
      "30600 bottleneck files created.\n",
      "30700 bottleneck files created.\n",
      "30800 bottleneck files created.\n",
      "30900 bottleneck files created.\n",
      "31000 bottleneck files created.\n",
      "31100 bottleneck files created.\n",
      "31200 bottleneck files created.\n",
      "31300 bottleneck files created.\n",
      "31400 bottleneck files created.\n",
      "31500 bottleneck files created.\n",
      "31600 bottleneck files created.\n",
      "31700 bottleneck files created.\n",
      "31800 bottleneck files created.\n",
      "31900 bottleneck files created.\n",
      "32000 bottleneck files created.\n",
      "32100 bottleneck files created.\n",
      "32200 bottleneck files created.\n",
      "32300 bottleneck files created.\n",
      "32400 bottleneck files created.\n",
      "32500 bottleneck files created.\n",
      "32600 bottleneck files created.\n",
      "32700 bottleneck files created.\n",
      "32800 bottleneck files created.\n",
      "32900 bottleneck files created.\n",
      "33000 bottleneck files created.\n",
      "33100 bottleneck files created.\n",
      "33200 bottleneck files created.\n",
      "33300 bottleneck files created.\n",
      "33400 bottleneck files created.\n",
      "33500 bottleneck files created.\n",
      "33600 bottleneck files created.\n",
      "33700 bottleneck files created.\n",
      "33800 bottleneck files created.\n",
      "33900 bottleneck files created.\n",
      "34000 bottleneck files created.\n",
      "34100 bottleneck files created.\n",
      "34200 bottleneck files created.\n",
      "34300 bottleneck files created.\n",
      "34400 bottleneck files created.\n",
      "34500 bottleneck files created.\n",
      "34600 bottleneck files created.\n",
      "34700 bottleneck files created.\n",
      "34800 bottleneck files created.\n",
      "34900 bottleneck files created.\n",
      "35000 bottleneck files created.\n",
      "35100 bottleneck files created.\n",
      "35200 bottleneck files created.\n",
      "35300 bottleneck files created.\n",
      "35400 bottleneck files created.\n",
      "35500 bottleneck files created.\n",
      "35600 bottleneck files created.\n",
      "35700 bottleneck files created.\n",
      "35800 bottleneck files created.\n",
      "35900 bottleneck files created.\n",
      "36000 bottleneck files created.\n",
      "36100 bottleneck files created.\n",
      "36200 bottleneck files created.\n",
      "36300 bottleneck files created.\n",
      "36400 bottleneck files created.\n",
      "36500 bottleneck files created.\n",
      "36600 bottleneck files created.\n",
      "36700 bottleneck files created.\n",
      "36800 bottleneck files created.\n",
      "36900 bottleneck files created.\n",
      "37000 bottleneck files created.\n",
      "37100 bottleneck files created.\n",
      "37200 bottleneck files created.\n",
      "37300 bottleneck files created.\n",
      "37400 bottleneck files created.\n",
      "37500 bottleneck files created.\n",
      "37600 bottleneck files created.\n",
      "37700 bottleneck files created.\n",
      "37800 bottleneck files created.\n",
      "37900 bottleneck files created.\n",
      "38000 bottleneck files created.\n",
      "38100 bottleneck files created.\n",
      "38200 bottleneck files created.\n",
      "38300 bottleneck files created.\n",
      "38400 bottleneck files created.\n",
      "38500 bottleneck files created.\n",
      "38600 bottleneck files created.\n",
      "38700 bottleneck files created.\n",
      "38800 bottleneck files created.\n",
      "38900 bottleneck files created.\n",
      "39000 bottleneck files created.\n",
      "39100 bottleneck files created.\n",
      "39200 bottleneck files created.\n",
      "39300 bottleneck files created.\n",
      "39400 bottleneck files created.\n",
      "39500 bottleneck files created.\n",
      "39600 bottleneck files created.\n",
      "39700 bottleneck files created.\n",
      "39800 bottleneck files created.\n",
      "39900 bottleneck files created.\n",
      "40000 bottleneck files created.\n",
      "INFO:tensorflow:Summary name cross entropy is illegal; using cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    "%run retrain.py \\\n",
    "--bottleneck_dir=bottlenecks \\\n",
    "--how_many_training_steps 1000 \\\n",
    "--learning_rate 0.001 \\\n",
    "--threshold -0.05 \\\n",
    "--model_dir=model_dir \\\n",
    "--output_graph=retrained_graph.pb \\\n",
    "--output_labels=retrained_labels.txt \\\n",
    "--summaries_dir=retrain_logs \\\n",
    "--image_dir=images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学习速率是0.00005的时候 训练的准确率在50%左右，变化很小,但预测的结果几乎都一样，存在过拟合觉得。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PredictImage import PredictImage\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm  import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from PIL import Image\n",
    "from os import PathLike\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isValidImage(file): \n",
    "    bValid = True\n",
    "    fileObj = open(file, 'rb')\n",
    "    buf = fileObj.read()\n",
    "    if buf[6:10] in (b'JFIF', b'Exif'):     #jpg图片\n",
    "        if not buf.rstrip(b'\\0\\r\\n').endswith(b'\\xff\\xd9'):\n",
    "            bValid = False\n",
    "    else:        \n",
    "        try:  \n",
    "            Image.open(fileObj).verify() \n",
    "        except:  \n",
    "            bValid = False         \n",
    "    return bValid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPredictResult(threshold):\n",
    "    predictImage = PredictImage()\n",
    "    pathDir = './test/'\n",
    "    testImages =  os.listdir(pathDir)[0:500]\n",
    "    imageIds = []\n",
    "    labels = []\n",
    "    with tqdm(total=len(testImages)) as bar:\n",
    "        for testImage in testImages:\n",
    "            imageId = int(testImage[0:-4])\n",
    "            imageIds.append(imageId)\n",
    "            imagepath = pathDir + testImage\n",
    "            if isValidImage(imagepath):\n",
    "        #print(imagepath)\n",
    "                l = predictImage.predictResult(imagepath, t = threshold)\n",
    "                label = ''.join([c + ' ' for c in l])\n",
    "                a = label.rstrip()\n",
    "                labels.append(a)\n",
    "            else:\n",
    "                labels.append(' ') \n",
    "            bar.update(1)\n",
    "    dataframe = pd.DataFrame({'image_id':imageIds,'label_id':labels})\n",
    "    dataframe.to_csv('predictResult.csv',sep = ',', index = False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████                               | 114/500 [03:52<13:07,  2.04s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-2b8fd90c65a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgetPredictResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.53\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-16-1138ef2503d1>\u001b[0m in \u001b[0;36mgetPredictResult\u001b[1;34m(threshold)\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m                 \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0mbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mdataframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'image_id'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mimageIds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'label_id'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mdataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'predictResult.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tqdm\\_tqdm.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m                     \u001b[1;31m# Print bar update\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1024\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1026\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tqdm\\_tqdm.py\u001b[0m in \u001b[0;36mprint_status\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mprint_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m             \u001b[0mlen_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m             \u001b[0mfp_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\r'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ms\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_len\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m             \u001b[0mlast_len\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen_s\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tqdm\\_tqdm.py\u001b[0m in \u001b[0;36mfp_write\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfp_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m             \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_unicode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m             \u001b[0mfp_flush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\colorama\\ansitowin32.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__convertor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\colorama\\ansitowin32.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_and_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\colorama\\ansitowin32.py\u001b[0m in \u001b[0;36mwrite_and_convert\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    167\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_ansi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[0mcursor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_plain_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\colorama\\ansitowin32.py\u001b[0m in \u001b[0;36mwrite_plain_text\u001b[1;34m(self, text, start, end)\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mflush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    319\u001b[0m             \u001b[0mevt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthreading\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEvent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mevt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "getPredictResult(0.53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def strToArray(data):\n",
    "    out = []\n",
    "    for i in data:\n",
    "     if i != '':\n",
    "        out.append(int(i))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getF1Score():\n",
    "    dfPredict = pd.read_csv(\"./predictResult.csv\")\n",
    "    dfValidation = pd.read_csv(\"./validation.csv\")\n",
    "    dfPredict = dfPredict.sort_values(by = 'image_id', ascending=True)\n",
    "    dfValidation = dfValidation.sort_values(by = 'image_id',ascending = True)\n",
    "    dfPredict.head()\n",
    "    dfValidation.head()\n",
    "    m,n = dfPredict.shape\n",
    "    maxLabel = 226\n",
    "    F1_scores = np.zeros(m,dtype = np.float)\n",
    "   # y_tAll = np.zeros(maxLabel,dtype='i4')\n",
    "   # y_pAll = np.zeros(maxLabel,dtype='i4')\n",
    "    for i in range(m):\n",
    "        image_id = dfPredict.loc[i,'image_id']\n",
    "        if(type(dfPredict.loc[i,'label_id'])!=str):\n",
    "          #  y_p = np.zeros(maxLabel,dtype ='i4')\n",
    "            y_pred = []\n",
    "        else:\n",
    "            y_pred = strToArray((dfPredict.loc[i,'label_id']).split(' '))\n",
    "        if(type(dfValidation.loc[i,'label_id'])!=str):\n",
    "            y_true = []\n",
    "        else:\n",
    "            y_true = strToArray((dfValidation.loc[i,'label_id']).split(' '))\n",
    "        y_t = np.zeros(maxLabel,dtype='i4')\n",
    "        if(y_true != []):\n",
    "            index = np.array(y_true)-1\n",
    "            y_t[index] = 1\n",
    "       # y_tAll =  y_tAll + y_t\n",
    "        y_p = np.zeros(maxLabel,dtype ='i4')\n",
    "        if(y_pred != []):\n",
    "            index = np.array(y_pred) - 1\n",
    "            y_p[index] = 1\n",
    "        TP = np.sum(y_t * y_p,axis = 1)\n",
    "        FP = np.sum(y_p, axis = 1) - TP\n",
    "        FN = np.sum(np.maximum(y_t - y_p,0), axis = 1)\n",
    "        precision = TP/(TP + FP)\n",
    "        recall = TP/(TP + FN)\n",
    "        F1_scores += precision * recall * 2 /(precision + recall  + 1e-10)\n",
    "    f1 = np.mean(F1_scores)\n",
    "       # y_pAll = y_p * p_t\n",
    "       # f1 = np.mean(np.sum(y_pAll))\n",
    "        #y_pAll = y_pAll + y_p\n",
    "    #f1 = f1_score(y_tAll, y_pAll, average='micro')\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 500/500 [06:58<00:00,  1.27it/s]\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'y_pred' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-68d6931fb1be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mgetPredictResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetF1Score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mF1_Scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-17b90bdd0ebd>\u001b[0m in \u001b[0;36mgetF1Score\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0my_tAll\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0my_tAll\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my_t\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0my_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaxLabel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m'i4'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0my_p\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'y_pred' referenced before assignment"
     ]
    }
   ],
   "source": [
    "threshold = [0.65]\n",
    "#(0.52, 0.469,)(0.54,0.543)(0.56,0.5789)(0.58,0.5789)(0.60,0.5789)(0.62,0.5833)(0.63,0.46)(0.60,0.464)(0.65,0.464)(0.61,0.34)\n",
    "#(0.62,0.34)(0.65,0.28)\n",
    "#new()\n",
    "F1_Scores = []\n",
    "for i in threshold:\n",
    "    getPredictResult(i)\n",
    "    f1 = getF1Score()\n",
    "    F1_Scores.append(f1)\n",
    "    print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "j = json.load(open(\"../data/origindata/validation.json\"))\n",
    "annotations = {}\n",
    "annotations = j['annotations']\n",
    "imageIds = []\n",
    "labels = []\n",
    "for annotation in annotations:\n",
    "    imageIds.append(int(annotation['imageId']))\n",
    "    l = annotation['labelId']\n",
    "    label = ''.join([c + ' ' for c in l])\n",
    "    a = label.rstrip()\n",
    "    labels.append(a)\n",
    "dataframe = pd.DataFrame({'image_id':imageIds,'label_id':labels})\n",
    "dataframe.to_csv('validation.csv',sep = ',', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>66 105 153 17 171 106 214 138 222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>2</td>\n",
       "      <td>66 105 153 17 171 106 214 138 222 62 53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>3</td>\n",
       "      <td>66 105 153 17 171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>4</td>\n",
       "      <td>66 105 153 17 106 171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>5</td>\n",
       "      <td>66 105 153 17 171 106 214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_id                                 label_id\n",
       "0           1        66 105 153 17 171 106 214 138 222\n",
       "111         2  66 105 153 17 171 106 214 138 222 62 53\n",
       "222         3                        66 105 153 17 171\n",
       "333         4                    66 105 153 17 106 171\n",
       "345         5                66 105 153 17 171 106 214"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfPredict = pd.read_csv(\"./predictResult.csv\")\n",
    "dfValidation = pd.read_csv(\"./validation.csv\")\n",
    "dfPredict = dfPredict.sort_values(by = 'image_id', ascending=True)\n",
    "dfValidation = dfValidation.sort_values(by = 'image_id',ascending = True)\n",
    "dfPredict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 0 1]\n",
      "[0 0 1 0 1 1]\n",
      "[0 1 0 0 0 0]\n",
      "3\n",
      "3\n",
      "1\n",
      "0.5\n",
      "0.75\n",
      "0.6\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([0, 1, 2, 0, 1, 2]) #true\n",
    "y = tf.constant([0, 2, 1, 0, 0, 1]) #pred\n",
    "TP = tf.minimum(x,y)\n",
    "FP = tf.maximum(y - x, 0)\n",
    "FN = tf.maximum(x - y, 0)\n",
    "c = x - y\n",
    "#a = tf.abs(x)\n",
    "print(sess.run(TP))\n",
    "print(sess.run(FP))\n",
    "print(sess.run(FN))\n",
    "TPS = tf.reduce_sum(TP,axis = 0)\n",
    "FPS = tf.reduce_sum(FP,axis = 0)\n",
    "FNS = tf.reduce_sum(FN,axis = 0)\n",
    "tp = tf.reduce_sum(TPS)\n",
    "fp = tf.reduce_sum(FPS)\n",
    "fn = tf.reduce_sum(FNS)\n",
    "precision = tp/(tp + fp) \n",
    "recall = tp/(tp+ fn)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "print(sess.run(TPS))\n",
    "print(sess.run(FPS))\n",
    "print(sess.run(FNS))\n",
    "print(sess.run(precision))\n",
    "print(sess.run(recall))\n",
    "print(sess.run(f1))\n",
    "#b = tf.reduce_sum(x,axis = 0)\n",
    "#b.eval()\n",
    "#a = x.eval()\n",
    "#tensor_a=tf.convert_to_tensor(a)\n",
    "#print(sess.run(tensor_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Sample-based precision, recall, fscore is not meaningful outside multilabel classification. See the accuracy_score instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-490d41c31fdc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'samples'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#其实就是上面预测正确的样本数/总样本数\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mf1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[0;32m    712\u001b[0m     return fbeta_score(y_true, y_pred, 1, labels=labels,\n\u001b[0;32m    713\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 714\u001b[1;33m                        sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    715\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[0;32m    826\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'f-score'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    829\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0maverage\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'samples'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1084\u001b[1;33m         raise ValueError(\"Sample-based precision, recall, fscore is \"\n\u001b[0m\u001b[0;32m   1085\u001b[0m                          \u001b[1;34m\"not meaningful outside multilabel \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1086\u001b[0m                          \"classification. See the accuracy_score instead.\")\n",
      "\u001b[1;31mValueError\u001b[0m: Sample-based precision, recall, fscore is not meaningful outside multilabel classification. See the accuracy_score instead."
     ]
    }
   ],
   "source": [
    "y_true = [1,1, 1, 1, 0, 0, 0, 0,0,0,0,0]\n",
    "y_pred = [0,0, 1, 1, 1, 0, 0, 0,0,0,0,0]\n",
    "f1 = f1_score(y_true,y_pred, average='samples') #其实就是上面预测正确的样本数/总样本数\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5714285714285715"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 2 3 4 true\n",
    "# 1 1 1 1 0 0 0 0\n",
    "# 3 4 5\n",
    "# 0 0 1 1 1 0 0 0\n",
    "#TP = sum(t*t) 2\n",
    "#FP = sum(y) - tp  1\n",
    "#FN = maximum(t -y,0) 2\n",
    "#pr = 2/3\n",
    "#re = 2/2+2 = 0.5\n",
    "#f1 = \n",
    "(2/3)/(0.5+2/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'Tensor' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-f7dc9aebfd13>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mFP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeep_dims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mTP\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mFN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_t\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_p\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeep_dims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mprecision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTP\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTP\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mFP\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1e-10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mrecall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTP\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTP\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mFN\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1e-10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mF1_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprecision\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mrecall\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprecision\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrecall\u001b[0m  \u001b[1;33m+\u001b[0m \u001b[1;36m1e-10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'Tensor' and 'float'"
     ]
    }
   ],
   "source": [
    "y_t = tf.constant([[1,0,1,1,0,0,0,1,1,0,1,1,0,0,0,1],[1,1,0,1,0,0,1,0,1,1,0,1,0,0,1,0]])\n",
    "y_p = tf.constant([[1,0,1,1,0,0,0,0,1,1,0,1,0,0,0,0],[1,0,1,1,0,0,0,0,1,1,0,1,0,0,1,0]])\n",
    "TP = tf.reduce_sum(y_t * y_p,axis = 1,keep_dims = True)\n",
    "FP = tf.reduce_sum(y_p, axis = 1,keep_dims = True) - TP\n",
    "FN = tf.reduce_sum(tf.maximum(y_t - y_p,0), axis = 1,keep_dims = True)\n",
    "precision = TP/(TP + FP )\n",
    "recall = TP/(TP + FN )\n",
    "F1_scores = precision * recall * 2 /(precision + recall  + 1e-10)\n",
    "f1 = tf.reduce_mean(F1_scores)\n",
    "print(sess.run(f1))\n",
    "print(sess.run(TP))\n",
    "print(sess.run(FP))\n",
    "print(sess.run(FN))\n",
    "print(sess.run(precision))\n",
    "print(sess.run(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,1,0,0])\n",
    "b = np.array([0,1,1,0])\n",
    "c =a * b\n",
    "d = np.sum(c)\n",
    "print(d)\n",
    "d = np.mean(c)\n",
    "d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-20"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final f1_score accuracy = 0.34000\n"
     ]
    }
   ],
   "source": [
    "print('Final f1_score accuracy = %.5f' % (0.34))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
